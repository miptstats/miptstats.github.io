---
layout: default
title: "Phystech@DataScience - Спецкурс по анализу данных для всего Физтеха"
---
<section>
<div class="home">
<p style=”line-height:1.5; padding-top:10px; padding-bottom:500px”>

<h2>Phystech@DataScience, 2024</h2><br>

<b>Лекторы:</b> Алиса Воронова, Тимофей Жданович, Артём Логинов, Екатерина Латыпова <br>

<b>Время:</b> суббота 17:05-20:00. Аудитория поточная Цифра.<br>



 <b>Лекция 1 (03.02.24).</b> Организационные вопросы. Что такое анализ данных. Обзор задач анализа данных на примере историй из Мурмурландии. Повторение теории вероятностей. Обзор инструментов анализа данных: Jupyter, Numpy, Matplotlib. <br> 

<a target="_blank" href="ad_mipt/Организация.pdf">Организационные моменты</a><br>
<a target="_blank" href="ad_mipt/Пример задачи (kNN).pdf">Пример задачи (kNN)</a><br>
<a target="_blank" href="ad_mipt/kde_distr_new-compressed (1).pdf">Распределения </a><br>
<a target="_blank" href="ad_mipt/Оформление.pdf">Правила оформления</a><br><br>
 

<b>Лекция 2 (10.02.23).</b> Повторение Python. Обзор библиотек: numpy, matplotlib, pandas, scipy. <br> <br>
 
<b>Лекция 3 (17.02.23).</b> Задача регрессии. Линейная регрессия, метод наименьших квадратов. Работа с категориальными признаками. Знакомство с библиотекой sklearn. Метрики качества регрессионных моделей. <br> 

<a target="_blank" href="ad_mipt/linreg_2024.pdf">Линейная регрессия</a><br><br>


 


 
<!--
 <a target="_blank" href="ad_mipt/rules.pdf">Правила курса</a><br><br>



<b>Лекция 2 (11.02.23).</b> Распределения, их виды и примеры. Основные правила работы с данными. Разбор функционала Pandas на примере датасета "Титаник". Обзор библиотеки Scipy. <br> 


<a target="_blank" href="ad_fivt/lecture2_1.pdf">Презентация по работе с данными</a><br>

<a href="ad_fivt/titanik.html">Примеры работы с pandas и seaborn на данных Титаника</a><br>

<a href="ad_mipt/Data_analysis.html">Простейший анализ данных</a><br>

<a href="python.html">Библиотеки pandas и scipy</a><br><br>
 
<b>Лекция 3 (04.04.23).</b> Статистики и оценки. Свойства оценок: несмещенность, состоятельность, асимптотическая нормальность. Асимптотические доверительные интервалы. Практика на примере равномерного распределения.<br><br> 
 
<b>Лекция 4 (11.04.23).</b> Точные доверительные интервалы. Доверительный интервалы в номальной модели.<br><br> 
 
<b>Лекция 5 (18.04.23).</b> Метод Монте-Карло. Бутстреп, бутстрепные доверительные интервалы. Метод максимального правдоподобия. Метод Ньютона. <br><br> 
 
<b>Лекция 6 (25.04.23).</b> Проверка статистических гипотез. Критерий для проверки гипотез, уровень значимости критерия, мощность критерия, виды альтернатив. Критерий Вальда. Реальный уровень значимости, p-value.  <br><br> 



<b>Лекция 7 (01.04.23).</b> Множественная проверка гипотез. Дисперсионный анализ. Независимые и связные выборки. Повторение гипотез и критериев. AB-тест на проверку эффективности лекарства. Класс критериев t-test. Абсолютный и относительный t-test. Валидация критериев, АА-тест.<br> 

<a href="ad_mipt/ab_mipt.pdf">Презентация</a><br><br>
 
 <b>Лекция 8 (08.04.23).</b> Задача регрессии. Линейная регрессия, метод наименьших квадратов. Знакомство с библиотекой sklearn. Регуляризация модели: Ridge, Lasso, ElasticNet. Метрики качества регрессионных моделей.<br> 

<a href="ad_mipt/linreg.pdf">Презентация</a><br>
<a href="ad_mipt/linreg.html">Примеры работы с sklearn на данных медицинского страхования</a><br><br>
 
 <b>Лекция 9 (15.04.23).</b> Задача классификации. Бинарная классификация, логистическая регрессия. Градиентный спуск, стохастический градиентный спуск.<br> 

<a href="ad_mipt/logreg.pdf">Презентация</a><br>
<a href="ad_mipt/logreg.html">Логистическая регрессия в sklearn</a><br>
<a href="ad_mipt/gd.html">Градиентный спуск</a><br><br>

<b>Лекция 10 (22.04.23).</b> Решающие деревья, алгоритм построенеия дерева, критерий останова, плюсы и минусы деревьев. Ансамбли моделей, случайный лес. Многоклассовая классификация. Кросс-валидация.<br> 

<a href="ad_mipt/trees.pdf">Презентация</a><br>
<a href="ad_mipt/trees.html">Решающие деревья и случайный леc в sklearn</a><br>
<a href="ad_mipt/validation.html">Кросс-валидация</a><br><br>
 

<b>Лекция 11 (29.04.23).</b> Временные ряды. Прогнозирование временного ряда, сведение к задачи регрессии. Прямая и рекурсивная стратегии. Оценка качества моделей. Кросс-валидация для временных рядов.<br> 

<a href="ad_mipt/time_series.pdf">Презентация</a><br>
<a href="ad_mipt/time_series.html">Прогнозирование временных рядов</a><br><br>


 -->

 
 

<h3>Домашние задания</h3>

Дедлайны по домашним заданиям указаны в боте. <br><br>

<a href="ad_mipt/hw_intro_2024.html">Задание 1.</a><br><br>
<a href="ad_mipt/hw3_2024_final.html">Задание 3.</a><br><br>

 <!--
<a href="ad_mipt/hw2_2023.html">Задание 2.</a><br><br>

<a href="ad_mipt/hw3.html">Задание 3.</a><br><br>
 
 <a href="ad_mipt/hw4.html">Задание 4.</a><br><br>
 
 <a href="ad_mipt/hw5.html">Задание 5.</a><br><br>
 
 <a href="ad_mipt/hw6.html">Задание 6.</a><br><br>
 
 <a href="ad_mipt/hw7.html">Задание 7.</a><br><br>
 
 <a href="ad_mipt/hw8.html">Задание 8.</a>
 <a href="ad_mipt/physics_data.csv" download=''>Данные для профиля 'физика'</a><br><br>
 
 <a href="ad_mipt/hw9.html">Задание 9.</a><br><br>
 
 <a href="ad_mipt/hw10.html">Задание 10.</a><br><br>
 
 <a href="ad_mipt/hw11.html">Задание 11.</a><br><br>
 
 <a href="ad_mipt/hw12.html">Задание 12.</a><br><br>
-->








<!--

<h3>Экзамен</h3><br>

Экзамен проводится для тех, кто был замечен в списывании, и не признался в этом в установленные сроки. Информация отправлена персонально каждому. Программа экзамена выложена на wiki-странице курса.

18 июня экзамен начнется в 12:00 по ссылке, которая отправлена в чат курса. Для сдачи необходимо отметиться по ссылке в чате. Экзамен можно сдать в любую дату до 26 июня включительно, сообщив о своем желании не позднее чем за сутки.



<h3>О курсе</h3><br>

Мы будем выполнять задания на языке Python, можно пока улучшить его знание с помощью наших шпаргалок  <a href="https://mipt-stats.gitlab.io/courses/python.html
">Python для анализа данных</a>  <br><br>

Для регистрации на курс необходимо зарегистрироваться в телеграм-боте @miptstats_pds_bot и заполнить форму, предложенную ботом. Отборочные задания внизу страницы.<br>



<b> <a href="https://docs.google.com/document/d/1xbCS_ofGy-WzcjQjIkQFcBh5_SnLl0b7rMJFpQQqXA4/edit?usp=sharing">Cсылка на зум первых занятий</a>  (доступ к документу с физтех-почты) </b> <br>



<b>Лектор основной части:</b> Ольга Калиниченко<br>

<b>Контакты лектора:</b> kalinichenko.oi@phystech.edu<br>


<!-- <b>Время:</b> среда 19:00-21:00. По субботам консультации.<br> -->

<!--
<b>Начало: 11 февраля</b> <br>

<b>Лекция:</b> пятница 17:05-19:15. Очно, можно смотреть дистанционно. Аудитория: <b>Б.Физ.</b> Ссылка выше. Слушателям спецкурса крайне желательно подключаться онлайн.<br>
По уважительной причине возможен просмотр записей. <br>

<b>Семинар:</b><br>


Группа 1 17:05 432 ГК Латыпова Екатерина <br>
Группа 2 17:05 532 ГК Дженжер Святослав, Мадан Арина<br>
Группа 3 17:05 424 ГК Загребин Иван<br>
Группа 4 18:30 432 ГК Мадан Арина<br>
Онлайн 18:30 Ссылка в боте. Дженжер Святослав, Латыпова Екатерина<br>




<b> Пожалуйста, не приходите очно на занятия с симптомами ОРВИ/простуды/коронавируса и соблюдайте масочный режим! </b> <br>

<!-- <b>Ссылка на первые два занятия:</b> <a target="_blank" href="https://meet.google.com/scr-gapo-dne">meet.google.com/scr-gapo-dne</a>. Присоединяться необходимо только с аккаунта phystech.edu.<br> -->

<!--<b>Начало:</b> 10 февраля<br>-->

<!--
<b>Телеграм-бот:</b> @miptstats_pds_bot<br><br>


Количество мест <b>ограничено</b>, будет организован отбор.


Материалы и видеозапись первых двух занятий будут в открытом доступе.<br><br><br>

<h3>Анонс</h3><br>

Приглашаем вас на спецкурс по математической статистике и основам анализа данных! В этом курсе мы познакомимся с основными понятиями статистики и машинного обучения и научимся применять полученные знания на практике. Вы узнаете, как законы теории вероятностей применяются в прикладной статистике и машинном обучении. <br><br>

Курс рассчитан на <b>два семестра</b>: в весеннем семестре вы познакомитесь с математической статистикой, основами анализа данных и машинного обучения, а затем в осеннем сконцентрируетесь на машинном обучении. <br><br>

В нашем курсе будет <b>три профиля</b>: физика, биология и педагогика. При наличии желающих может быть также организован теоретический профиль. Курс  будет состоять из общих лекций и практических заданий, а также для каждого профиля в отдельности будет несколько специальных лекций и прикладных задач. Особое внимание будет уделено практике, в том числе применению статистики и анализа данных в реальных физических и биологических задачах. <br><br>

<b>Каждому слушателю курса необходимо выбрать один из профилей</b>. Для студентов 1 курса магистратуры кафедры инновационной педагогики спецкурс обязателен с профилем педагогика. Для студентов 2 курса ЛФИ, у которых курс обязателен, - профиль физика.  <br><br>


Статистика, анализ данных и машинное обучение в настоящее время активно применяются во многих разделах физики: от физики частиц до поиска новых объектов на снимках космоса. Например, в ЦЕРНе многие эксперименты не обходятся без анализа данных и построения моделей методами машинного обучения (<a target="_blank" href="https://nplus1.ru/material/2017/10/25/cern-yandex">подробнее</a>). Другой пример: построение моделей для предсказания различных параметров нейтрино по “сырым” данным их траекторий, полученных детектором.  <br><br>

<p align="center"><img height="500" src="ad_mipt/1.png"></p>  <br>

Анализ данных также является необходимым навыком для современных ученых-биологов. Резкий скачок в объеме данных произошел относительно недавно, количество людей, которые умеют правильно применять статистические методы и методы анализа данных в биологии, невелико. Примеры задач: оценка дифференциальной экспрессии генов, анализ данных single-cell RNA sequencing, функциональная аннотация генома, медицинские исследования и многое другое! <br><br>


<p align="center"><img height="500" src="ad_mipt/2.png"><img height="500" src="ad_mipt/3.png"></p>  <br>


Помимо знания физики/биологии для всех этих задач необходимо понимать основы статистики и машинного обучения. Кроме того, чтобы правильно интерпретировать свои данные и гипотезы, необходимо не просто уметь применять разные статистические тесты и методы машинного обучения, но и понимать границы и специфику их применимости. Обо всем этом мы поговорим на курсе. Спецкурс поможет получить базовое понимание в этой области, а также понять, интересно ли вам это направление для более глубокого изучения. А еще вы наконец-то узнаете глубинный смысл формул для оценок, погрешностей и метода наименьших квадратов, к которым вы так привыкли на лабах! <br><br>

Курс успешно прошел в 2021 году, и по отзывам участников оказался крайне интересным, полезным и актуальным. Студенты уже активно применяют полученные знания в научных исследованиях.

<br> 


<h3>Особенности</h3><br>

<b>Предполагается, что слушатели обладают базовыми понятиями теории вероятностей!</b><br><br>


Формальное название курса – <b>“Прикладная статистика”</b>, кафедра дискретной математики ФПМИ. Оценку по курсу можно зачесть с помощью отрывного или инд. плана с помощью замен курсов. Последнее – при согласии физтех-школы и базовой кафедры.<br><br>

В силу ограниченных возможностей проверяющих на курс будет организован отбор по результатам первых двух домашних заданий. Отбор не затрагивает студентов кафедры инновационной педагогики и 2 курса ЛФИ, для которых курс обязателен. Дополнительная информация по структуре курса для этих студентов - на лекции! <br><br>


Если вы хотите взять курс в инд. план, но отбор еще не прошел, а ваша физтех-школа не позволяет ждать, свяжитесь с лектором, вам будет выслана дополнительная важная информация. В инд плане указывайте номер РУП: 31 001 <br><br>

<h3>Лекции 2022</h3><br>

<b>Вводная лекция  (11.02.2022).</b> Введение, обзор задач анализа данных, реальные примеры. Непараметрические методы статистики: гистограммы, ядерные оценки плотности. Параметрические методы: статистики и оценки. <br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/1FeQ3Tkp8TTluTqAB5Rg6rj3EkgtasgPv/preview" width="640" height="360"></iframe><br><br>

<a target="_blank" href="ad_mipt/lecture1_2022_.pdf">Презентация</a><br>

<a target="_blank" href="ad_mipt/Коты.pdf">Обзор задач статистики</a><br>

<a href="ad_mipt/lec1_notebook.html">Пример простейшего анализа данных</a><br>

<b>Лекция 2 (18.02.2022).</b> Линейная регрессия, свойства оценок. <br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/15V68BZuZz-lwlAVH2DXAWkikXv_TjOuA/preview" width="640" height="360"></iframe><br><br>

<a href="ad_mipt/lec2.pdf">Презентация</a><br>

<h3>Домашние задания</h3><br>

<a target="_blank" href="https://docs.google.com/spreadsheets/d/15V0Q_f6tG22tvROapDhzQex0FrNgl1Qw-Os42eUD3WE/edit?usp=sharing">Задать вопрос по заданию</a><br><br>

Для сдачи заданий необходимо <b>заранее</b> зарегистрироваться в телеграм-боте @miptstats_pds_bot <br><br> 

После регистрации для сдачи задания через бот надо нажать кнопку </b>/start</b> и следовать указаниям.  <br> 

Результаты Яндекс.Контеста учитываются только по логину (адрес яндекс-почты), указанному при регистрации! <br> <br> 

Для отбора надо сдать обе части задания 1 + Задание 2(выдается в пт). Часть заданий - это контест, часть - в боте. В боте нажимаете на соответствующую кнопку (сдаете вы по отбору или обязательный курс, у кнопок разный дедлайн)  <br> <br> 

<b>ССЫЛКА В БОТЕ!!! Задание 1 а. Яндекс-Контест. (Базовый, основной потоки и отбор) </b> Дедлайн 23 февраля в 22:00.<br><br>   

<a href="ad_mipt/task1_2022.html"><b>Задание 1 б. (Основной поток и отбор).</b></a> Дедлайн отбора 20 февраля в 22:00. Дедлайн по обязательному курсу 23 февраля в 22:00<br><br> 


<a href="ad_mipt/task2_2022.html"><b>Задание 2. (Основной поток и отбор).</b></a> Дедлайн отбора 26 февраля в 22:00. Дедлайн по обязательному курсу 28 февраля в 22:00<br><br> 


 <!---

<a href="ad_mipt/task2.html"><b>Задание 2.</b></a> Дедлайн 26 февраля в 22:00.<br><br> -->


<!--
<h3>Форма записи на курс</h3>

Следующие лекции будут выкладываться на Яндекс.Вики. При наличии большого количества желающих будет проведен отбор на курс. Дедлайн по заполнению формы 1 марта 23:59.<br>

<script src="https://yastatic.net/q/forms-frontend-ext/_/embed.js"></script><iframe src="https://forms.yandex.ru/u/6036a3386ea1d4c26938919f/?iframe=1" frameborder="0" name="ya-form-6036a3386ea1d4c26938919f" width="650"></iframe> <br><br>

-->


<h3>Дополнительные материалы</h3>

Всех материалов с занятий будет хватать для выполнения почти всех домашних заданий. В случае, если есть желание углубиться в тему глубже, рекомендуем материалы из списка ниже.

<ul>
 <li><a target="_blank" href="https://mml-book.github.io/">Mathematics for Machine Learning</a></li>
 <li>Python Data Analysis: Comprehensive Guide to Data Science, Analytics and Metrics with Python (Alex Campbell)</li>
 <li>Python Foundation this book includes Python for beginners, Machine Learning, Python Data Science.</li>
 <li>Наглядная математическая статистика (Лагутин)</li>
 <li>All of Statistics (Wasserman)</li>
 <li><a target="_blank" href="https://academy.yandex.ru/handbook/ml">Учебник по машинному обучению от ШАД</a></li>
 <li>Core Concepts in Data Analysis: Summarization, Correlation, Visualization (Boris Mirkin)</li>
 <li><a target="_blank" href="https://www.statlearning.com/">An Introduction to Statistical Learning</a> (James, Witten, Hastie, Tibshirani) </li>
</ul>


<h3>Анонимные отзывы</h3>

<script src="https://yastatic.net/s3/frontend/forms/_/embed.js"></script><iframe src="https://forms.yandex.ru/u/63f265de02848f8105386f1a/?iframe=1" frameborder="0" name="ya-form-63f265de02848f8105386f1a" width="650"></iframe>

<!--
<script src="https://yastatic.net/q/forms-frontend-ext/_/embed.js"></script><iframe src="https://forms.yandex.ru/u/6028dbc698f7286f7bf06c3d/?iframe=1" frameborder="0" name="ya-form-6028dbc698f7286f7bf06c3d" width="650"></iframe>

<h3>Лекции 2021</h3><br>

<b>Вводная лекция 1 (10.02.2021).</b> Введение, обзор задач анализа данных, реальные примеры. Непараметрические методы статистики: гистограммы, ядерные оценки плотности. Параметрические методы: статистики и оценки. <br>

<a target="_blank" href="ad_mipt/lecture1.pdf">Презентация</a><br>

<a href="ad_mipt/lec1_notebook.html">Пример простейшего анализа данных</a><br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/1T6uTcBHuKOXIJwor8NWgBkUsxl3X-JCr/preview" width="640" height="360"></iframe><br><br>

<b>Вводная лекция 2 (17.02.2021).</b> Линейная регрессия, метод наименьших квадратов. Методы на основе ближайших соседей. Простые метрики регрессии и классификации. <br>

<a target="_blank" href="ad_mipt/lecture2.pdf">Презентация</a><br>

<a href="ad_mipt/lec2_linreg.html">Линейная регрессия</a><br>

<a href="ad_mipt/lec2_knn.html">Метод k ближайших соседей.</a><br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/18N0ohx71t-xK44Z1GAJCgSyvYPpgqNWL/preview" width="640" height="360"></iframe><br><br>

<b>Лекция 3 (24.02.2021).</b> Теория точечного оценивания. Свойства оценок параметров, наследование свойств. Метод максимального правдоподобия. <br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/138a0EIUa_UwgIyDQT0KUDEtflei1Q127/preview" width="640" height="360"></iframe><br><br>

<b>Материалы следующих занятий находятся в закрытом доступе.</b><br><br>
-->

</p>
</div>
</section>
