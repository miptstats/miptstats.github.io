{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a href=\"https://miptstats.github.io/courses/ad_mipt.html\">Phystech@DataScience</a>\n",
    "## Домашнее задание 4\n",
    "\n",
    "**Правила, <font color=\"red\">прочитайте внимательно</font>:**\n",
    "\n",
    "* Выполненную работу нужно отправить телеграм-боту `@miptstats_pds_bot`. Для начала работы с ботом каждый раз отправляйте `/start`. **Работы, присланные иным способом, не принимаются.**\n",
    "* Дедлайн см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Прислать нужно ноутбук в формате `ipynb`.\n",
    "* Выполнять задание необходимо полностью самостоятельно. **При обнаружении списывания все участники списывания будут сдавать устный зачет.**\n",
    "* Решения, размещенные на каких-либо интернет-ресурсах, не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
    "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n",
    "* Комментарии к решению пишите в markdown-ячейках.\n",
    "* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n",
    "* Если код будет не понятен проверяющему, оценка может быть снижена.\n",
    "* Никакой код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n",
    "* **Код из рассказанных на занятиях ноутбуков можно использовать без ограничений.**\n",
    "\n",
    "**Правила оформления теоретических задач:**\n",
    "\n",
    "* Решения необходимо прислать одним из следующих способов:\n",
    "  * фотографией в правильной ориентации, где все четко видно, а почерк разборчив,\n",
    "    * отправив ее как файл боту вместе с ноутбуком *или*\n",
    "    * вставив ее в ноутбук посредством `Edit -> Insert Image` (<font color=\"red\">фото, вставленные ссылкой, не принимаются</font>);\n",
    "  * в виде $\\LaTeX$ в markdown-ячейках.\n",
    "* Решения не проверяются, если какое-то требование не выполнено. Особенно внимательно все проверьте в случае выбора второго пункта (вставки фото в ноутбук). <font color=\"red\"><b>Неправильно вставленные фотографии могут не передаться при отправке.</b></font> Для проверки попробуйте переместить `ipynb` в другую папку и открыть его там.\n",
    "* В решениях поясняйте, чем вы пользуетесь, хотя бы кратко. Например, если пользуетесь независимостью, то достаточно подписи вида \"*X и Y незав.*\"\n",
    "* Решение, в котором есть только ответ, и отсутствуют вычисления, оценивается в 0 баллов.\n",
    "\n",
    "**Баллы за задание:**\n",
    "\n",
    "<b><font color=\"blue\">Легкая часть</font></b> (достаточно на \"хор\"):\n",
    "* Задача 1 &mdash; 50 баллов\n",
    "* Задача 2 &mdash; 50 баллов\n",
    "\n",
    "\n",
    "<b><font color=\"orange\">Сложная часть</font></b> (необходимо на \"отл\"):\n",
    "* Задача 3 &mdash; 30 баллов\n",
    "* Задача 4 &mdash; 20 баллов\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bot check\n",
    "\n",
    "# HW_ID: phds_hw4\n",
    "# Бот проверит этот ID и предупредит, если случайно сдать что-то не то.\n",
    "\n",
    "# Status: not final\n",
    "# Перед отправкой в финальном решении удали \"not\" в строчке выше.\n",
    "# Так бот проверит, что ты отправляешь финальную версию, а не промежуточную.\n",
    "# Никакие значения в этой ячейке не влияют на факт сдачи работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "sns.set_theme(palette='Set2')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b><font color=\"blue\">Легкая часть</font></b>\n",
    "\n",
    "### Задача 1\n",
    "\n",
    "\n",
    "#### 1. Загрузка данных и предобработка\n",
    "\n",
    "#### *Профиль биология*\n",
    "\n",
    "Загрузите [данные](https://miptstats.github.io/courses/ad_mipt.html) по предсказанию рака груди. Поодробнее о них можно почитать в [источнике](https://www.kaggle.com/datasets/marshuu/breast-cancer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('breast_cancer.csv')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте, имеются ли в ваших данных пропуски. Если да, то удалите их.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека `pandas` позволяет строить графики `matplotlib` для своих объектов `DataFrame` ([подробнее](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)). Посмотрим, как распределены значения признака `Bare Nuclei` для разных классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "data.groupby(\"Class\")['Bare Nuclei'].hist(ax=axs[0], alpha=0.5)\n",
    "data.groupby(\"Class\")['Bare Nuclei'].plot(kind='kde', ax=axs[1])\n",
    "axs[0].set_title('Гистограмма для Bare Nuclei', fontsize=20)\n",
    "axs[1].set_title('KDE для Bare Nuclei', fontsize=20);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем отличаются способы построения ЯОП и гистограммы? Какую информацию о наших данных можно извлечь из каждого графика?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте гистограммы и ядерные оценки плотности для всех признаков из датасета отдельно для каждого класса. `Class` — целевая переменная. Можно это сделать, опираясь на код выше, а можно воспользоваться параметром `hue` у функции [`sns.histplot`](https://seaborn.pydata.org/generated/seaborn.histplot.html) или другим методом, который вам нравится. Не забывайте подписывать, к чему относится каждый график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие выводы вы можете сделать из полученных графиков?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** <...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Это не конец задачи! Переходите к пункту 2!**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Профиль физика*\n",
    "\n",
    "Загрузите данные по бинарной классификации астероидов в зависимости от различных параметров с <a href=\"https://miptstats.github.io/courses/ad_mipt.html\">сайта</a>.\n",
    "\n",
    "Вашей целевой переменной будет являться столбец `pha`. Более подробно ознакомить с датасетом вы можете также [здесь](https://www.kaggle.com/datasets/sakhawat18/asteroid-dataset/data). Можно заметить, что наш датасет сильно меньше по размерам, чем оригинал. Это сделано намеренно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_savaged.csv')\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека `pandas` позволяет строить графики `matplotlib` для своих объектов `DataFrame` ([подробнее](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)). Посмотрим, как распределены значения признака `rms` для разных классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 7))\n",
    "data.groupby(\"pha\")['rms'].hist(ax=axs[0], alpha=0.5)\n",
    "data.groupby(\"pha\")['rms'].plot(kind='kde', ax=axs[1])\n",
    "axs[0].set_title('Гистограмма для rms', fontsize=20)\n",
    "axs[1].set_title('KDE для rms', fontsize=20);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем отличаются способы построения ЯОП и гистограммы? Какую информацию о наших данных можно извлечь из каждого графика?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** <...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте гистограммы и ядерные оценки плотности для указанных ниже признаков отдельно для каждого класса. `Class` — целевая переменная. Можно это сделать, опираясь на код выше, а можно воспользоваться параметром `hue` у функции [`sns.histplot`](https://seaborn.pydata.org/generated/seaborn.histplot.html) или другим методом, который вам нравится. Не забывайте подписывать, к чему относится каждый график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['epoch', 'ma', 'tp', 'rms']\n",
    "<...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие выводы вы можете сделать из полученных графиков?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**<...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Обучение модели\n",
    "\n",
    "Продолжайте использовать выбранные вами данные."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте массив признаков и массив таргета. Разбейте ваши данные на обучающую и тестовую выборки в отношении 7:3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = <...>\n",
    "y = <...>\n",
    "X_train, X_test, y_train, y_test = <...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените стандартизацию к обучающей и тестовой выборкам, используя класс <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler\">`StandardScaler`</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объясните, что делает `StandardScaler` и почему его нельзя обучать на тестовой выборке?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте предсказание для тестовой выборки и оцените качества полученного предсказания, рассмотрите метрики: `accuracy_score`, `precision` и `recall`.\n",
    "\n",
    "Если названия ваших классов отличаются от 0 и 1, то надо использовать аргумент `pos_label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем ли порадоваться таким результатам? Вернемся к гистограммам и сделаем вывод, почему метрики оказались такими большими. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Учтём дисбаланс классов\n",
    "Давайте посмотрим на распределение наших данных по целевой переменной по всему датасету, тренировочной и тестовой выборках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = <...>.value_counts() # Колонка таргета из изначального датасета\n",
    "train = <...>.value_counts() # Колонка таргета из тренировочного датасета\n",
    "test = <...>.value_counts() # Колонка таргета из тестового датасета\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "sns.barplot(x=original.index, y=original.values, ax=axes[0], palette=['blue'])\n",
    "axes[0].set_title('Распределение классов в data')\n",
    "axes[0].set_ylabel('Количество')\n",
    "\n",
    "sns.barplot(x=train.index, y=train.values, ax=axes[1], palette=['green'])\n",
    "axes[1].set_title('Распределение классов в train')\n",
    "\n",
    "sns.barplot(x=test.index, y=test.values, ax=axes[2], palette=['orange'])\n",
    "axes[2].set_title('Распределение классов в test')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в данных есть сильный перекос — классы представлены неравномерно. Как и почему это повлияло на наши результаты?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** <...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть много способов борьбы с этим. Можно искусственно сгенерировать данные нужного класса или урезать другой класс. Однако сегодня мы воспользуемся ***взвешенной*** логистической регрессией. Суть метода заключается в том, чтобы вручную поставить веса для классов, исходя из их предполагаемой природы: важность разных классов, цена ошибки в реальной жизни (например, что хуже: предсказать наличие рака, если он есть или нет?) и представленность данных.\n",
    "\n",
    "Функция потерь &mdash; в нашем случае логарифм функции правдоводобия &mdash; для взвешенной логистической регресси будет записана как:\n",
    "\n",
    "$$\n",
    "L(y, \\widehat{y}) = \\sum_{i=1}^{N} w_{y_i} \\cdot \\left[ y_i \\cdot \\log(\\sigma(\\widehat{y}_i)) + (1 - y_i) \\cdot \\log(1 - \\sigma(\\widehat{y}_i)) \\right]\n",
    "$$\n",
    "\n",
    "где:\n",
    "\n",
    "\n",
    "- $ y_i $ - истинный класс для образца  $i$\n",
    "- $ \\widehat{y}_i $ - предсказанный класс для образца $i$\n",
    "- $ w_{y_i} $ - вес класса\n",
    "\n",
    "\n",
    "\n",
    "Давайте реализуем этот метод. Допишите код и в качестве весов класса  поставьте соотношение их представленности. Выведите подсчет количества экземпляров каждого класса и посчитайте их соотношение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = <...>\n",
    "class_weights = {<класс_1>: threshold, <класс_2>: 1 - threshold}\n",
    "# если использовать class_weights = 'balanced', модель сама подсчитает веса\n",
    "\n",
    "weighted_model = LogisticRegression(class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте метрики качества. `Accuracy` посчитайте двумя способами: без учёта и [с учётом весов](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "<...>\n",
    "print(f\"accuracy = {accuracy} \\nprecision = {precision} \\nrecall = {recall}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как изменилось качество нашей модели? Почему надо учитывать несбалансированность данных?\n",
    "\n",
    "Сделайте общий вывод по задаче."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Вам предлагается изучить и сравнить свойства линейных регрессионных моделей: обычной и с регуляризациями &mdash; `Lasso`, `Ridge`, `Elastic Net`.  \n",
    "\n",
    "При выполнении задания воспользуйтесь готовыми реализациями методов в `sklearn`. Функции, описанные ниже, пригодятся вам во втором пункте этого задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coef(model, X, y, log_min, log_max, \n",
    "               num):\n",
    "    \"\"\"\n",
    "    Данная функция считает коэффициенты для признаков \n",
    "    при различных значениях параметра регуляризации.\n",
    "\n",
    "    :param model: регрессионная модель\n",
    "    :param X: матрица регрессоров\n",
    "    :param y: вектор целевой переменной\n",
    "    :param log_min, log_max: логарифмы левой и правой границ диапазона для коэффициента регуляризации\n",
    "    :param num: число точек из диапазона\n",
    "\n",
    "    :return coefs: коэффициенты модели\n",
    "    \"\"\"\n",
    "    \n",
    "    alphas = np.logspace(log_min, log_max, num) # сетка параметров   \n",
    "    coefs = [] # коэффициенты моделей\n",
    "    for a in alphas:\n",
    "        if 'l1_ratio' in model.get_params(): # для ElasticNet\n",
    "            # равномерно распределим alpha по обоим коэффициентам\n",
    "            a *= 3/2\n",
    "            model.set_params(alpha=a) # переопределяем параметры модели\n",
    "        else:\n",
    "            model.set_params(alpha=a)\n",
    "        model.fit(X, y)\n",
    "        # отбираем только первые 20 признаков для ускорения работы кода\n",
    "        coefs.append(model.coef_[:20]) \n",
    "    return coefs\n",
    "\n",
    "def draw_track(coefs, log_min, log_max, \n",
    "               num, title='', figsize=(10, 5)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Данная функция строит график зависимости значений \n",
    "    коэффициентов модели от параметра регуляризации.\n",
    "    \n",
    "    :param coefs: коэффициенты модели\n",
    "    :param log_min, log_max: логарифмы левой и правой границ диапазона для коэффициента регуляризации\n",
    "    :param num: число точек из диапазона\n",
    "    :param title: название графика\n",
    "    :param figsize: размеры рисунка\n",
    "\n",
    "    :return coefs: коэффициенты модели\n",
    "    \"\"\"\n",
    "    alphas = np.logspace(log_min, log_max, num) # сетка параметров  \n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.gca() # используется для получения текущего экземпляра axes\n",
    "    ax.hlines(0, 10 ** log_min, 10 ** log_max, linewidth=15, alpha=0.15)\n",
    "    ind = 1\n",
    "    for coef in np.array(coefs).T:\n",
    "        label = r'$\\theta_{' + str(ind) + '}$'\n",
    "        ax.plot(alphas, coef, linewidth=2, label=label) # рисуем коэффициенты в зависимости от alpha\n",
    "        ind += 1\n",
    "        \n",
    "    ax.set_xscale('log') # логарифмическая шкала\n",
    "    ax.set_xlim(ax.get_xlim()[::-1])  # обратить ось\n",
    "    plt.xlabel('Параметр регуляризации', fontsize=19)\n",
    "    plt.ylabel('Значения коэффициентов', fontsize=19)\n",
    "    plt.title(title, fontsize=22)\n",
    "    plt.legend(loc='upper left', fontsize=8)\n",
    "    plt.axis('tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Загрузка данных\n",
    "\n",
    "#### *Профиль биология*\n",
    "\n",
    "Скачайте данные с [сайта](https://miptstats.github.io/courses/ad_mipt.html). Оригинал вместе с описанием можно найти [здесь](https://archive.ics.uci.edu/ml/datasets/Parkinsons+Telemonitoring). Сами данные лежат в `Data Folder`. Файл `.data` можно читать с помощью `read_csv`. В этой задаче мы хотим предсказать уровень выраженности болезни Паркинсона в зависимости от параметров речи пациента. В датасете есть записи о 42 пациентах, для каждого некотрое количество записей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('parkinsons_updrs.data', sep=',')\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нас интересует предсказание `total_UPDRS` &mdash; степени заболевания. Для корректной постановки задачи удалите из данных столбец `motor_UPDRS`, так как это тоже мера тяжести заболевания, но лишь в аспекте моторных нарушений. Будем предсказывать значение `total_UPDRS` в зависимости от остальных признаков. \n",
    "\n",
    "Также обратите внимане, что в данных есть группы (пациенты). Колонку `subject#` следует использовать не в качестве признака, а в качестве группы. Разделите данные на признаки $X$, таргет $y$ и массив номеров групп."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте данные на обучающую и тестовую выборки в соотношении 7:3. Здесь не подойдет стандартный метод `test_train_split`, так как в данных есть группы. *Нельзя допускать, чтобы разные записи для одного пациента попали в разные подвыборки*.\n",
    "\n",
    "**Также, выведите что-либо, подтверждающее данное свойство.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data[\"subject#\"]\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_index, test_index = next(gss.split(X, y, groups=groups))\n",
    "<...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее везде, вплоть до сравнения моделей в задаче 3, используйте обучающую выборку. \n",
    "\n",
    "**Переходите к пункту 2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Профиль физика*\n",
    "\n",
    "Загрузите данные с <a href=\"https://miptstats.github.io/courses/ad_mipt.html\">сайта</a>. Данные были предобработаны и сокращены для более быстрой работы алгоритмов предсказания, так как в этом задании их будет большое кол-во. С исходными данными вы можете ознакомиться <a href=\"https://www.kaggle.com/datasets/burakhmmtgl/energy-molecule\">здесь</a>.\n",
    "\n",
    "В таблице находятся записи в кулоновской матрице в сжатом виде, которые действуют как молекулярные признаки. 0-я колонка — это Pubchem Id, по этому числу вы можете понять, для какой молекулы приведены числа. Этот столбец возьмем в качестве индекса строк. Последний столбец `Eat` — это энергия распыления, рассчитанная путем моделирования с использованием пакета Quantum Espresso. Этот столбец и является целевой переменной.\n",
    "\n",
    "*Для интересующихся: cнижение размерности пространства признаков проводилось с помощью <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\">метода главных компонент</a>*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('physics_data.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите данные на признаки $X$ и целевые переменные $y$. **Для дальнейших заданий оставьте 20 признаков.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите выборку в отношении 7:3. Далее везде, вплоть до сравнения моделей, используйте обучающую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = <...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее везде, вплоть до сравнения моделей в задаче 3, используйте обучающую выборку. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Влияние регуляризации на коэффициенты моделей\n",
    "\n",
    "Примените стандартизацию к обучающей и тестовой выборкам, используя класс <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler\">`StandardScaler`</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Исследуйте зависимость значений коэффициентов от параметра регуляризации `alpha` для Ridge, Lasso, Elastic регрессий. Используйте функции `calculate_coefs` и `draw_track`, реализованные в самом начале этой задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуйте графики. Предложите диапазоны значений, где стоило бы искать оптимальные параметры регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge регрессия\n",
    "# инициализация и обучение моддели\n",
    "ridge_model = <...>\n",
    "\n",
    "# коэффициенты регрессии\n",
    "ridge_coefs = <...>\n",
    "\n",
    "# отрисовка\n",
    "<...>\n",
    "\n",
    "\n",
    "# Lasso регрессия\n",
    "lasso_model = <...>\n",
    "lasso_coefs = <...>\n",
    "<...>\n",
    "\n",
    "# Elastic регрессия\n",
    "elastic_model = <...>  # установите какое-то значение l1_ratio\n",
    "elastic_coefs = <...>\n",
    "<...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрите, как выглядят графики без стандартизации. Почему так происходит?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b><font color=\"orange\">Сложная часть</font></b>\n",
    "### Задача 3\n",
    "\n",
    "\n",
    "Эта задание является продолжением предыдущего. Здесь не нужно загружать новые данные, продолжайте работать с выбранными вами данными.\n",
    "\n",
    "**1.** Для Elastic исследуйте зависимость от параметра `l1_ratio`. Постройте график изменения весов признаков в зависимости от `l1_ratio` для первых 20 признаков из датасета. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = <...>\n",
    "coefs = <...>\n",
    "model = <...>\n",
    "\n",
    "for l1_ratio in grid:\n",
    "    <...> # Задайте новый параметр модели\n",
    "    <...> # Обучите\n",
    "    <...># Добавьте в список\n",
    "\n",
    "# Для визуализации можно использовать код из функции draw_track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предложите диапазоны значений, где стоило бы искать оптимальные параметры регуляризации."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Проиллюстрируйте, как меняется качество предсказания моделей при изменении параметра `alpha`. Возьмите `Ridge`, `Lasso` и 3 `ElasticNet` с разными фиксированными значениями `l1_ratio` &mdash; вы будете исследовать 5 моделей с регуляризацией и 1 без нее."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Физика:*** Для этого задания возьмите полный датасет &mdash; все 300 признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала посчитайте ошибки для линейной регрессии без регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = {}\n",
    "linreg['MSE'] = mean_squared_error(<...>)\n",
    "linreg['MAE'] = mean_absolute_error(<...>)\n",
    "linreg['MAPE'] = mean_absolute_percentage_error(<...>)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допишите функцию для отрисовки изменения величины ошибки от параметра регуляризации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_errors(error, error_name, alphas):\n",
    "\n",
    "    \"\"\"\n",
    "    Функция строит график зависимости величины ошибки от параметра alpha для разных моделей\n",
    "    \n",
    "    :param error: функция, вычисляющая ошибку\n",
    "    :param error_name: имя функции, вычисляющей ошибку (одно из 'MSE', 'MAE', 'MAPE')\n",
    "    :param alphas: массив величин alpha\n",
    "    \"\"\"\n",
    "    arr = [] # массив ошибок\n",
    "    for a in alphas:\n",
    "        tmp = [] # массив ошибок\n",
    "        models = [<Ваши модели с заданными парметрами>] \n",
    "        for model in models:\n",
    "            \n",
    "            # обучение модели и предсказание \n",
    "            y_pred = <...>\n",
    "            tmp.append(error(y_test, y_pred))\n",
    "        arr.append(tmp)\n",
    "\n",
    "    arr = np.array(arr)\n",
    "    plt.figure(figsize=(10, 6), dpi=100)\n",
    "\n",
    "    names = <Имена моделей с заданными параметрами> \n",
    "    for i in range(5):\n",
    "        plt.plot(alphas, arr[:, i], label=names[i]) # рисуем ошибки в зависимости от alpha\n",
    "\n",
    "    # прерывистой линией рисуем ошибки логрега без регуляризации\n",
    "    plt.hlines(linreg[error_name], alphas[0], alphas[-1], color='black', label = 'No regularization', linestyles='dashed')\n",
    "    plt.xlabel('Параметр регуляризации')\n",
    "    plt.ylabel(error_name)\n",
    "    plt.xscale('log')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики для MSE, MAE и MAPE. Возьмите предложенный массив `alphas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-2, 8, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вложите в функции метрики\n",
    "draw_errors(<...>)\n",
    "draw_errors(<...>)\n",
    "draw_errors(<...>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцените по графикам, в каких диапазонах достигается наилучшее качетсво предсказания моделей. Постройте графики для более узкого диапазона, чтобы сравнить модели более детально."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Сделайте общий вывод по задаче. \n",
    "\n",
    "Укажите: в чем разница между `L1` и `L2` регуляризациями, как реализуется регуляризация в `ElasticNet`, что такое `l1-ratio` и зачем нужен, как это видно в наших графиках. (Своими словами)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** <...>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 4\n",
    "\n",
    "\n",
    "Регуляризацию успользуют не только в задачах регрессии, но и в задачах классификации.\n",
    "\n",
    "Пусть дана выборка $(x_1, Y_1), ..., (x_n, Y_n)$, где $x_i = (x_{i1}, ..., x_{id}) \\in \\mathscr{X}$ и случайный класс $Y_i \\sim Bern\\left(\\sigma (\\theta^T x_i)\\right)$. В задаче логистической регрессии максимизируется функция *правдоподобия*, а точнее - ее логарифм.\n",
    "$$L_Y (\\theta)= \\prod\\limits_{i=1}^n \\sigma (\\theta^T x_i)^{Y_i} \\left(1 - \\sigma (\\theta^T x_i)\\right)^{1-Y_i}$$\n",
    "\n",
    "$$\\ell_Y(\\theta) = \\log L_Y(\\theta)$$\n",
    "\n",
    "$$\\ell_Y(\\theta) \\longrightarrow \\max_\\theta.$$\n",
    "Регуляризация заключается в искусственном усечении значений вектора оценок коэффициентов путем добавления его нормы к оптимизируемому функционалу. В случае логистической регрессии мы максимизируем функцию правдоподобия, поэтому норма добавляется со знаком минус. Тем самым решается задача\n",
    "$$\\ell_Y(\\theta) - \\lambda \\|\\theta\\|^2\\longrightarrow \\max_\\theta,$$\n",
    "где $\\lambda > 0$ &mdash; гиперпараметр модели, то есть число, которое задается пользователем. Мы получили логистическую регрессию c **$l_2$-регуляризацией**.\n",
    "\n",
    "*Замечание.* Такая модель дает некоторое *другое приближение* неизвестной зависимости. Но неправильно думать, что она не может дать \"правильный\" ответ, потому такого понятия как \"правильный ответ\" в подобных задачах не существует. Можно получить только *более качественное приближение*,согласно выбранной метрике."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите формулу поиска оценки коэффициентов методом *градиентного подъёма* и *стохастического градиентного подъёма* для \n",
    "- модели логистической регрессии без регуляризации\n",
    "- модели логистической регрессии c ridge-регуляризацией"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
