---
layout: default
title: "Введение в анализ данных"
---
<section>
<div class="home">

<h2>Введение в анализ данных, 2024</h2><br>

<b>Лекторы:</b> Никита Волков, Алексей Горбулев, Лидия Троешестова, Ксения Мелещеня<br>

<b>Время:</b> суббота 17:05-20:00.<br>

Начало 3 февраля. Курс проходит очно <b>в поточной аудитории корпуса Арктика</b>. <!--Посещать занятия можно дистанционно, но по возможности желательно очно. До начала занятия надо зарегистрироваться в телеграм-боте <a target="_blank" href="https://t.me/miptstats_ds22_bot">@miptstats_ds22_bot</a>.<br>-->


Кафедра <a target="_blank" href="https://mipt.ru/education/chairs/dm/">дискретной математики</a>.<br><br> 


Организационная информация находится в презентации с первой лекции.<br><br><br> 


<!--
<h3>Пересдача.</h3>

До 30 сентября 23:59 нужно заполнить <a target="_blank" href="https://forms.gle/Sv879JtFPuSSYXAG6">форму</a>.<br> <br> 
-->

<h3>Лекции</h3>

<b>Лекция 1 (3.02.24).</b> О курсе, DS-поток. Что такое анализ данных. Обзор задач анализа данных на примере историй из Мурмурландии. Метод ближайшего соседа на примере решения задачи классификации на два класса. Примеры реальных задач: рекомендательная система, продуктовая аналитика, синтез речи. <br> 

<a target="_blank" href="ad_fivt/lecture1.pdf">Презентация</a><br>
<a target="_blank" href="ad_fivt/lecture1_2.pdf">Презентация по выполнению и оформлению домашних заданий</a><br>

<a href="ad_fivt/lec1_announce.html">Анонс следующей лекции</a><br>


<a href="https://disk.yandex.ru/i/Uj7_hRmnCX4K1w">Видео</a><br><br><br>



<b>Лекция 2 (10.02.24).</b> Дополнительная необязательная онлайн лекция по библиотекам Питона. Относится к программе обязательной части курса. Ссылка для подключения будет разослана в телеграм-боте.<br><br>

<i>Все упражнения в материалах этой лекции не влияют на оценку, сдавать их не нужно.</i><br><br>

Библиотеки:<br><br>

<a href="ad_fivt/05_numpy.html">Библиотека Numpy</a><br>
<a href="ad_fivt/black.html">Библиотека Black</a><br>
<a href="ad_fivt/06_matplotlib.html">Библиотека Matplotlib</a><br>
<a href="ad_fivt/08_pandas1.html">Библиотека pandas — типы данных Series и DataFrame, запись и чтение файлов, работа с датами.</a><br>
<a href="ad_fivt/09_seaborn.html">Библиотека seaborn.</a><br><br>

Примеры на данных:<br><br>
<a href="ad_fivt/titanik.html">Примеры работы с pandas и seaborn на данных Титаника</a><br><br>

Другие материалы при наличии времени:<br><br>
<a href="python/10_pandas2.html">Библиотека pandas — объединение таблиц, группировки, таблицы сопряженности и сводные таблицы.</a><br>
<a href="python/11_plotly.html">Библиотека Plotly — построение интерактивных графиков.</a><br><br>


<a href="https://disk.yandex.ru/i/7zibweKxEbJo8Q">Видео</a><br><br><br>




<b>Лекция 3 (17.02.24).</b> Особенности работы с табличными данными. Модель линейной регрессии, метод наименьших квадратов, формула в общем случае. Градиентный спуск, его применение к методу наименьших квадратов, стохастический градиентный спуск.<br>

<a target="_blank" href="ad_fivt/lecture3_1.pdf">Презентация по работе с данными</a><br>

<a href="ad_fivt/lecture3_2.pdf">Презентация по модели линейной регрессии</a><br>

<a href="ad_fivt/linreg_sklearn.html">Линейная регрессия с помощью sklearn</a><br>

<a href="ad_fivt/lecture3_3.pdf">Пайплайн ML-моделей.</a><br>

<a href="https://disk.yandex.ru/i/KxmCOsT7FtlVIw">Видео</a><br><br>





<b>Лекция 4 (02.03.24).</b> Нейрон. Связь нейрона с линейной регрессией. Полносвязный слой нейронной сети. Однослойные и двухслойные нейронные сети. Теорема Цыбенко. Обучение нейронных сетей. Примеры применения различных нейронных сетей.<br>

<a target="_blank" href="ad_fivt/lecture4.pdf">Презентация</a><br>

<a href="ad_fivt/nn_simple_examples.html">PyTorch и полносвязные нейронные сети</a><br>

<a href="ad_fivt/nn_complex_examples.html">Применение различных нейросетевых моделей</a><br>

<a href="https://disk.yandex.ru/i/BpBHrX6wczOJzQ">Видео</a><br><br>




<b>Лекция 5 (09.03.24).</b> Классификация изображений. Стандартное представление изображения. Свёртка, Pooling. Предсказание вероятности.<br>

<a target="_blank" href="ad_fivt/lecture5_1.pdf">Презентация</a><br>

<a href="ad_fivt/CV_classification.html">Ноутбук</a><br>
<br>

Перенос стиля. Генерация произвольных изображений. Upsampling. GAN. Диффузионные модели. Обзор задач в CV.<br>

<a target="_blank" href="ad_fivt/lecture5_2.pdf">Презентация</a><br>

<a href="ad_fivt/CV_complex_examples.html">Ноутбук</a><br><br>

<a href="https://disk.yandex.ru/i/YCg66V__NHWpnQ">Видео</a><br><br>






<b>Лекция 6 (16.03.24).</b> Введение в NLP. Кодирование текстов: Bag of Words, Word2Vec. Основные модели: 1D-свертка, RNN, Large Language Models (LLM). Примеры задач.<br>

<a target="_blank" href="ad_fivt/lecture6.pdf">Презентация</a><br>

<a href="ad_fivt/nlp_sem.html">Рекуррентные нейронные сети</a><br>

<a href="ad_fivt/nlp_sem_llama.html">Генерация текста с помощью модели LLAMA</a><br>

<a href="https://disk.yandex.ru/i/Kwois0Zlhewv1w">Видео</a><br><br>






<b>Лекция 7 (30.03.24).</b> Гостевая лекция от Яндекса.

<a href="https://disk.yandex.ru/i/Lr51ViwTrXkxVg">Видео</a><br><br>






<b>Лекция 8 (6.04.24).</b> Задача кластеризации: постановка задачи, особенности, требования к форме кластеров, метрики качества. Метод кластеризации KMeans. Понижение размерности с помощью метода главных компонент (PCA), проклятие размерности.<br>

<a target="_blank" href="ad_fivt/lecture8.pdf">Презентация</a><br>

<a href="ad_fivt/pca.html">Понижение размерности</a><br>

<a href="ad_fivt/clustering.html">Кластеризация: простые примеры и текстовые ответы на вопросы в боте</a><br>

<a href="https://disk.yandex.ru/i/gCAzVK6zRislEA">Видео</a><br><br>






<b>Лекция 9 (13.04.23).</b> Вероятностные распределения и их свойства с практической точки зрения, генерация случайных чисел. Свойство независимости на практике применительно к понятию выборки, пример выборки, не являющейся независимой. Примеры о способах усреднения данных, медиана, мода. Свойство отсутствия памяти. Пример исследования реальных данных, время ожидания автобуса по реальным данным.<br> 

<a target="_blank" href="ad_fivt/lecture9.pdf">Презентация</a><br>

<a target="_blank" href="ad_fivt/lecture9_2.pdf">Важность оформления материалов: примеры</a><br>

<a href="python/07_random.html">Работа со случайными величинами в Питоне</a><br>

<a href="ad_fivt/lec9_means.html">Что такое среднее и как с ним правильно работать</a><br>

<a href="ad_fivt/lec9_bus.html">Парадокс времени ожидания на реальных данных</a><br>

<a href="ad_fivt/lec9_LLN.html">Закон больших чисел</a><br>

<!--<a href="https://disk.yandex.ru/i/YGvmF61uos1VHQ">Видео</a><br><br>-->




<br>




<br>










<!--

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/1mCZzBLnfBvzY65Oe5tYVHGNfJRvV4Iwp/preview" width="640" height="360"></iframe><br><br> 
-->

<!--<b>Лекция 2 (11.02.23).</b> Особенности работы с табличными данными. <br> 

<a target="_blank" href="ad_fivt/lecture2_1.pdf">Презентация по работе с данными</a><br>

<a href="ad_fivt/titanik.html">Примеры работы с pandas и seaborn на данных Титаника</a><br>

<a href="ad_fivt/data_parsing.html">Работа с API и парсинг данных из HTML</a><br>

<a target="_blank" href="ad_fivt/lecture2_2.pdf">Презентация по выполнению и оформлению домашних заданий</a><br>

<a href="https://disk.yandex.ru/i/GQ1B3p2TbO4ozQ">Видео</a><br><br> 




<b>Лекция 3 (4.03.23).</b> Вероятностные распределения и их свойства с практической точки зрения, генерация случайных чисел. Свойство независимости на практике применительно к понятию выборки, пример выборки, не являющейся независимой. Примеры о способах усреднения данных, медиана, мода. Свойство отсутствия памяти. Пример исследования реальных данных, время ожидания автобуса по реальным данным.<br> 

<a target="_blank" href="ad_fivt/lecture3.pdf">Презентация</a><br>

<a href="python/07_random.html">Работа со случайными величинами в Питоне</a><br>

<a href="ad_fivt/lec3_means.html">Что такое среднее и как с ним правильно работать</a><br>

<a href="ad_fivt/lec3_bus.html">Парадокс времени ожидания на реальных данных</a><br>

<a href="ad_fivt/lec3_LLN.html">Закон больших чисел</a><br>

<a href="https://disk.yandex.ru/i/YGvmF61uos1VHQ">Видео</a><br><br>




<b>Лекция 4 (11.03.23).</b> Модель линейной регрессии, метод наименьших квадратов, формула в общем случае. Градиентный спуск, его применение к методу наименьших квадратов, стохастический градиентный спуск.<br>

<a href="ad_fivt/lecture4.pdf">Презентация по модели линейной регрессии</a><br>

<a href="ad_fivt/linreg_sklearn.html">Линейная регрессия с помощью sklearn</a><br>

<a href="ad_fivt/ML_pipeline.pdf">Пайплайн ML-моделей.</a><br>

<a href="https://disk.yandex.ru/i/yRmWFwS-nkepEQ">Видео</a><br><br> 



<b>Лекция 5 (18.03.23).</b> Гостевая лекция от Яндекса: "Путь аналитика в Яндексе: чем занимаются аналитики и зачем они нужны."<br><br>


<b>Лекция 6 (25.03.23).</b> Решающие деревья для регрессии и классификации. Построение дерева, критерии остановки. Случайный лес.<br>

<a target="_blank" href="ad_fivt/lecture6.pdf">Презентация</a><br>

<a href="ad_fivt/trees.html">Решающие деревья и случайные леса с помощью sklearn</a><br>

<a href="https://disk.yandex.ru/i/8PM8A6hSPqPdgA">Видео</a><br><br> 


<b>Лекция 7 (01.04.23).</b> Задача оценки параметра. Метод моментов. Cильно состоятельные оценки, выборочное среднее и выборочная дисперсия.<br>

<a href="ad_fivt/estimators.html">Исследование оценок для экспоненциального распределения</a><br>


<a href="https://disk.yandex.ru/i/ZwQLd4BxEPghiA">Видео</a><br><br> 


<b>Лекция 8 (15.04.23).</b> Постановка задачи классификации, байесовские классификаторы. Линейный и квадратичный дискриминантный анализы, наивный Байес. Оптимальность байесовского классификатора.<br>

<a href="ad_fivt/bayes_classification.html">Байесовские классификаторы с помощью sklearn</a><br><br> 


<a href="https://disk.yandex.ru/i/b1JJaxgft3cgYA">Видео</a><br><br> 





<b>Лекция 9 (22.04.23).</b> Нейрон. Связь нейрона с линейной регрессией. Полносвязный слой нейронной сети. Однослойные и двухслойные нейронные сети. Теорема Цыбенко. Обучение нейронных сетей. Примеры применения различных нейронных сетей.<br>

<a target="_blank" href="ad_fivt/lecture9.pdf">Презентация</a><br>

<a href="ad_fivt/nn_simple_examples.html">PyTorch и полносвязные нейронные сети</a><br>

<a href="ad_fivt/nn_complex_examples.html">Применение различных нейросетевых моделей</a><br>

<a href="https://disk.yandex.ru/i/9vH98Bc5JRHGKw">Видео</a><br><br>





<!--
Видео доступно под аккаунтом phystech.edu. <i>До 0:40 происходит дублирование звука.</i><br>

<iframe src="https://drive.google.com/file/d/1-JQ7fwhXuHMsBtpmPpNpnb77-SXnyTpN/preview" width="640" height="360"></iframe><br><br>



<b>В субботу 19.02.22 занятия нет.</b> Вы выполняете домашние задания, а также при необходимости изучаете <a href="https://mipt-stats.gitlab.io/courses/python.html">видеоматериал</a> по библиотекам. <br><br>

<b>Лекция 3 (26.02.22). Гостевая лекция от Яндекса.</b> Даниил Тарарухин, руководитель группы Аналитики монетизации геосервисов. "Путь аналитика в Яндексе: чем занимаются аналитики и зачем они нужны."<br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/1BQaUvunuXxywYucFcbFaWjT_u-Droh2d/preview" width="640" height="360"></iframe><br><br>









<b>Лекция 4 (5.03.22).</b> Вероятностные распределения и их свойства с практической точки зрения, генерация случайных чисел. Свойство независимости на практике применительно к понятию выборки, пример выборки, не являющейся независимой. Примеры о способах усреднения данных, медиана, мода. Свойство отсутствия памяти. Пример исследования реальных данных, время ожидания автобуса по реальным данным.<br> 

<a target="_blank" href="ad_fivt/lecture4.pdf">Презентация</a><br>

<a href="python/07_scipy_stats.html">Библиотека scipy.stats</a><br>

<a href="ad_fivt/lec4_means.html">Что такое среднее и как с ним правильно работать</a><br>

<a href="ad_fivt/lec4_bus.html">Парадокс времени ожидания на реальных данных</a><br>

<a href="ad_fivt/lec4_LLN.html">Закон больших чисел</a><br>

<a href="ad_fivt/plotly.html">Построение интерактивных графиков с помощью plotly</a><br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/1FVJVCDZNHf__R4AX9CrcUJ1dVd-qlfps/preview" width="640" height="360"></iframe><br><br>


<b>Лекция 5 (12.03.22).</b> Модель линейной регрессии, метод наименьших квадратов, формула в общем случае. Градиентный спуск, его применение к методу наименьших квадратов, стохастический градиентный спуск.<br>

<a href="ad_fivt/linreg.pdf">Презентация по модели линейной регрессии</a><br>

<a href="ad_fivt/linreg_sklearn.html">Линейная регрессия с помощью sklearn</a><br>

<a href="ad_fivt/ML_pipeline.pdf">Пайплайн ML-моделей.</a><br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/1NvZuo1Njak7YothWkVhjZc0bjPucI2nj/preview" width="640" height="360"></iframe><br><br>



<b>Лекция 6 (19.03.22).</b> Решающие деревья для регрессии и классификации. Построение дерева, критерии остановки. Случайный лес.<br>

<a target="_blank" href="ad_fivt/lecture6.pdf">Презентация</a><br>

<a href="ad_fivt/trees.html">Решающие деревья и случайные леса с помощью sklearn</a><br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/19OwJgWemTyMI0xfrLNJyHHUbWurRd7yW/preview" width="640" height="360"></iframe><br><br>



<b>Лекция 7 (26.03.22).</b> Задача оценки параметра. Метод моментов. Cильно состоятельные оценки, выборочное среднее и выборочная дисперсия.<br>

<a href="ad_fivt/estimators.html">Исследование оценок для экспоненциального распределения</a><br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/1Z6kIxdKD1547_3z-lc6ZjmGw1ypNxgF-/preview" width="640" height="360"></iframe><br><br>


<b>Лекция 8 (02.04.22).</b> Постановка задачи классификации, байесовские классификаторы. Линейный и квадратичный дискриминантный анализы, наивный Байес. Оптимальность байесовского классификатора.<br>

<a href="ad_fivt/bayes_classification.html">Байесовские классификаторы с помощью sklearn</a><br>

Видео доступно под аккаунтом phystech.edu<br>

<iframe src="https://drive.google.com/file/d/1QwNjJqTuHR7UOWqj7Ju-PTTyH5PZao9v/preview" width="640" height="360"></iframe><br><br>


<b>Лекция 9 (09.04.22).</b> Нейрон. Связь нейрона с линейной регрессией. Полносвязный слой нейронной сети. Однослойные и двухслойные нейронные сети. Теорема Цыбенко. Обучение нейронных сетей. Примеры применения различных нейронных сетей.<br>

<a target="_blank" href="ad_fivt/lecture9.pdf">Презентация</a><br>

<a href="ad_fivt/nn_simple_examples.html">PyTorch и полносвязные нейронные сети</a><br>

<a href="ad_fivt/nn_complex_examples.html">Применение различных нейросетевых моделей</a><br>

Видео скоро будет.<br><br>



-->




<h3>Домашние задания</h3>

Дедлайны по домашним заданиям указаны в боте. <br><br>

<b>Задание 1.</b> <a href="ad_fivt/task1.html">Условие</a> <br><br>

<b>Задание 2.</b> <a href="ad_fivt/task2.html">Условие</a>, <a target="_blank" href="https://disk.yandex.ru/d/_P17svqa2qXR7g">данные</a><br><br>

<b>Задание 3.</b> <a href="ad_fivt/task3.html">Условие</a><br><br>

<b>Задание 4.</b> <a href="ad_fivt/task4.html">Условие</a><br><br>

<b>Задание 5.</b> <a href="ad_fivt/task5.html">Условие</a><br><br>

<b>Задание 6.</b> <a href="ad_fivt/task6.html">Условие</a><br><br>

<b>Задание 7.</b> <a href="ad_fivt/task7.html">Условие</a><br><br>

<b>Задание 8.</b> <a href="ad_fivt/task8.html">Условие</a><br><br>



<br>

<!--
a download="task2_data.zip" href="ad_fivt/task2_data.zip">данные</a><br><br>

<!--
<b>Задание 3.</b> <a href="ad_fivt/task3.html">Условие</a>, <a target="_blank" href="https://disk.yandex.ru/d/9WIX-cUTqILGzA">данные</a><br><br>

<b>Задание 4.</b> <a href="ad_fivt/task4.html">Условие</a><br><br>

<b>Задание 5.</b> <a href="ad_fivt/task5.html">Условие</a><br><br>

<b>Задание 6.</b> <a href="ad_fivt/task6.html">Условие</a><br><br>

<b>Задание 7.</b> <a href="ad_fivt/task7.html">Условие</a><br><br>

<b>Задание 8.</b> <a href="ad_fivt/task8.html">Условие</a><br><br>

<b>Задание 9.</b> <a href="ad_fivt/task9.html">Условие</a><br><br>

<b>Задание 10.</b> <a href="ad_fivt/task10.html">Условие</a><br><br>
 
-->


<!--

<h3>Факультативные домашние задания</h3>


<!---->



<h3>Дополнительные материалы</h3>

Всех материалов с занятий будет хватать для выполнения почти всех домашних заданий. В случае, если есть желание углубиться в тему глубже, рекомендуем материалы из списка ниже.

<ul>
 <li><a target="_blank" href="https://mml-book.github.io/">Mathematics for Machine Learning</a></li>
 <li>Python Data Analysis: Comprehensive Guide to Data Science, Analytics and Metrics with Python (Alex Campbell)</li>
 <li>Python Foundation this book includes Python for beginners, Machine Learning, Python Data Science.</li>
 <li><a target="_blank" href="https://academy.yandex.ru/handbook/ml">Учебник по машинному обучению от ШАД</a></li>
 <li>Core Concepts in Data Analysis: Summarization, Correlation, Visualization (Boris Mirkin)</li>
 <li><a target="_blank" href="https://www.statlearning.com/">An Introduction to Statistical Learning</a> (James, Witten, Hastie, Tibshirani) </li>
</ul>



<!--

https://christophm.github.io/interpretable-ml-book/

Interpretable Machine Learning
A Guide for Making Black Box Models Explainable

-->

<h3>Анонимные отзывы</h3>

<script src="https://yastatic.net/s3/frontend/forms/_/embed.js"></script>
<iframe src="https://forms.yandex.ru/u/62001eb89ae318f2377d1875/?iframe=1" frameborder="0" name="ya-form-62001eb89ae318f2377d1875" width="650"></iframe>


</div>
</section>
